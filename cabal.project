packages:
    .
library-stripping: True
executable-stripping: True
optimization: 2
executable-profiling: False
library-profiling: False
profiling: False
profiling-detail: late-toplevel
allow-newer: all
jobs: $ncpus
semaphore: True
split-sections: True
constraints: QuickCheck < 2.17
-- source-repository-package
--     type: git
--     location: https://github.com/haskell-unordered-containers/unordered-containers
--     tag: 213c64a1d2b7f75a5b2ae42576b77fc544b1160e
-- package hashable
--         flags: +arch-native
program-options
    ghc-options:
                 -mavx
                 -mavx2
                 -mbmi
                 -mbmi2
                 -msse
                 -msse2
                 -msse3
                 -msse4
                 -msse4.2
                 -mavx512cd
                 -fproc-alignment=64

                 -optc-O3
                 -opta-O3
                 -opta-flto=thin
                 -opta-fuse-linker-plugin
                 -opta-ffat-lto-objects
                 -opta-fauto-profile=profile.afdo
                 -optl-O3
                 -optl-fuse-linker-plugin
                 -optl-flto=thin
                 -optl-fuse-ld=gold
                 -optl-fauto-profile=profile.afdo
                 -optl--for-linker=--gc-sections
                 -optl--for-linker=-O3
                 -optl-ffat-lto-objects
                 -fsplit-sections
                 -funbox-strict-fields
                 -- inline aggressively to ensure lenses/polymorphic functions are fully saturated at concrete types
                 -- we're about 50% slower on the hot path when -fexpose-all-unfoldings, -fspecialise-aggressively,
                 -- and -fpolymorphic-specialisation are turned off -- despite all the manual INLINE/SPECIALIZE pragmas.
                 -fexpose-all-unfoldings
                 -fspecialize-aggressively
                 -flate-specialise
                 -fpolymorphic-specialisation
                 -fstatic-argument-transformation
                 -fspec-eval
                 -fspec-eval-dictfun
                 -flate-dmd-anal
                 -fdmd-unbox-width=20
                 -fdicts-cheap
                 -fdo-clever-arg-eta-expansion
                 -flocal-float-out
                 -flocal-float-out-top-level
                 -fspec-constr
                 -fspec-constr-keen
                 -- giving the specializer more room to chug makes the generated core more closely match the
                 -- source program. or at least, I can read it more easily and recognize what's happening
                 -- where.
                 -fmax-simplifier-iterations=32
                 -fsimplifier-phases=4
                 -fsimpl-tick-factor=800
                 -funfolding-case-threshold=16
                 -funfolding-case-scaling=1600
                 -funfolding-use-threshold=200
                 -funfolding-dict-discount=1600
                 -fmax-worker-args=20
                 -- -fstrictness-before=48
                 -- results in a mild speedup, ~5%
                 -fworker-wrapper-cbv
                 -- -ddump-rules
                 -- -ddump-rule-firings
                 -- -ddump-rule-rewrites
                 -ddump-simpl
                 -ddump-asm
                 -ddump-to-file
                 -dno-typeable-binds
                 -dsuppress-coercions
                 -dsuppress-idinfo
                 -dsuppress-module-prefixes
                 -dsuppress-type-applications
                 -dsuppress-timestamps
                 -dsuppress-ticks
                 -ddump-splices
                 -- -fforce-recomp
                 -rtsopts
                 -- -fprof-cafs
                 -- -threaded
                 -fomit-yields
